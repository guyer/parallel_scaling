from pathlib import Path
import pandas as pd
from matplotlib import pyplot as plt
import matplotlib

configfile: "config/config.yml"

include: "rules/common.smk"
include: "rules/aggregate.smk"
include: "rules/clone.smk"
include: "rules/permutations.smk"
include: "rules/solve.smk"

report: "report/workflow.rst"

simulation_file = Path(config["simulations"])
if simulation_file.exists():
    SIMULATIONS = pd.read_csv(simulation_file).set_index("id", drop=False)
else:
    SIMULATIONS = pd.DataFrame(columns=["fipy_rev", "suite", "id"])

globbed = glob_wildcards("results/fipy~{rev}/suite~{suite}/{id}/metrics.json")

rule all:
    localrule: True
    input:
        "results/plots/scaling.png",
        "results/plots/speedup.png"

rule all_permutations:
    output:
        "config/all_permutations.csv"
    input:
        benchmarks="config/benchmark_permutations.csv",
        fipy_revs="config/fipy_permutations.csv"
    run:
        benchmarks = pd.read_csv(input["benchmarks"], index_col=False)
        fipy_revs = pd.read_csv(input["fipy_revs"], index_col=False)
        df = benchmarks.join(fipy_revs, how="cross")
        df = df[~((df["solver"].isin(["LinearLUSolver", "LinearJORSolver"])
                  & (df["preconditioner"] != "none")))]
        df = df[~(df["preconditioner"] == "MultilevelSolverSmootherPreconditioner")]
        df.to_csv(output[0], index_label="id")

rule plot_scaling:
    localrule: True
    output:
        "results/plots/scaling.png"
    input:
        "results/all.json"
    run:
        matplotlib.use('Agg')

        df = pd.read_json(input[0])

        fig, ax = plt.subplots(figsize=(8,6))
        symbol = {
            "petsc": "xb",
            "no-pysparse": "+r",
            "pysparse": "^C1",
            "scipy": "vg"
        }
        line = {
            "a5f233aa7": "-",
            "371d28468": "--"
        }
        for (suite, fipy_rev), group in df.groupby(["suite", "fipy_rev"]):
            group.plot("tasks", "elapsed / s",
                       style=symbol[suite], linestyle=line[fipy_rev],
                       loglog=True, ax=ax, label=f"{suite}-{fipy_rev}")

        ax.set_ylabel("elapsed / s")
        fig.savefig(output[0])

rule plot_speedup:
    localrule: True
    output:
        "results/plots/speedup.png"
    input:
        "results/all.json"
    run:
        matplotlib.use('Agg')

        df = pd.read_json(input[0])

        fig, ax = plt.subplots(figsize=(8,6))
        symbol = {
            "petsc": "xb",
            "no-pysparse": "+r",
            "pysparse": "^C1",
            "scipy": "vg"
        }
        line = {
            "a5f233aa7": "-",
            "371d28468": "--"
        }
        baseline = df[(df["suite"] == "pysparse")
                      & (df["fipy_rev"] == "371d28468")].iloc[0]["elapsed / s"]
        df["speedup"] = baseline / df["elapsed / s"]
        for (suite, fipy_rev), group in df.groupby(["suite", "fipy_rev"]):
            group.plot("tasks", "speedup",
                       style=symbol[suite], linestyle=line[fipy_rev],
                       loglog=True, ax=ax, label=f"{suite}-{fipy_rev}")

        ax.set_ylabel("speedup / ($t_{PySparse} / t_N$)")
        fig.savefig(output[0])

rule bootstrap:
    input:
        expand("results/fipy~{rev}/suite~{suite}/environment.yml",
               rev=config["fipy_revs"],
               suite=config["suites"])

rule aggregate_all_results:
    output:
        "results/all.json"
    input:
        logs=expand("results/fipy~{rev}/suite~{suite}/{id}/metrics.json",
                    zip,
                    rev=SIMULATIONS["fipy_rev"],
                    suite=SIMULATIONS["suite"],
                    id=SIMULATIONS.index)
    log:
        "logs/aggregate_all_results.log"
    run:
        metrics = SIMULATIONS.apply(load_metrics, axis=1)
        df = pd.concat([SIMULATIONS, metrics], axis=1)
        df.to_json(output[0], date_format="iso")

rule aggregate_glob_results:
    output:
        "results/glob.json"
    input:
        logs=expand("results/fipy~{rev}/suite~{suite}/{id}/metrics.json",
                    zip,
                    rev=globbed.rev,
                    suite=globbed.suite,
                    id=globbed.id)
    log:
        "logs/aggregate_glob_results.log"
    run:
        subset = SIMULATIONS[globbed.id]
        metrics = subset.apply(load_metrics, axis=1)
        df = pd.concat([subset, metrics], axis=1)
        df.to_json(output[0], date_format="iso")

rule plot_permutations_timed:
    output:
        total="results/plots/all_permutations_timed.png",
    input:
        "results/all_permutations_timed.json"
    log:
        "logs/plot_permutations_timed.log"
    run:
        from workflow.scripts.plot_permutations import plot_all

        df = pd.read_json(input[0])
        plot_all(df, output.total, ymin=1e0, ymax=1e4)
